import streamlit as st
import os
import tempfile
import asyncio

# --- ASYNCIO DÃ–NGÃœSÃœ YAMASI ---
try:
    asyncio.get_running_loop()
except RuntimeError:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
# ------------------------------

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# Sayfa AyarlarÄ±
st.set_page_config(page_title="Orman Mevzuat AsistanÄ±", layout="wide", page_icon="ğŸŒ²")

st.title("ğŸŒ² Orman Mevzuat AsistanÄ± (AI)")
st.markdown("YÃ¶netmelik PDF'lerini yÃ¼kleyin ve sorun.")

# Yan MenÃ¼
st.sidebar.header("ğŸ“ Belge YÃ¼kle")

# API Key KontrolÃ¼
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    st.error("API AnahtarÄ± bulunamadÄ±.")
    api_key = None

uploaded_files = st.sidebar.file_uploader("PDF YÃ¼kle", accept_multiple_files=True, type="pdf")
process_button = st.sidebar.button("Belgeleri Ä°ÅŸle")

if process_button and uploaded_files:
    if not api_key:
        st.error("API AnahtarÄ± yok!")
    else:
        with st.spinner("Belgeler iÅŸleniyor... (Ä°lk seferde model indirildiÄŸi iÃ§in 1-2 dk sÃ¼rebilir)"):
            documents = []
            for uploaded_file in uploaded_files:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
                    temp_file.write(uploaded_file.read())
                    temp_file_path = temp_file.name

                loader = PyPDFLoader(temp_file_path)
                docs = loader.load()
                documents.extend(docs)
                os.remove(temp_file_path)

            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            splits = text_splitter.split_documents(documents)

            # HuggingFace Embedding (Yerel ve Ãœcretsiz)
            embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
            
            vector_store = FAISS.from_documents(splits, embeddings)
            st.session_state.vector_store = vector_store
            st.success(f"TamamlandÄ±! {len(splits)} parÃ§aya bÃ¶lÃ¼ndÃ¼.")

soru = st.text_input("Sorunuzu yazÄ±n:")

if soru:
    if "vector_store" not in st.session_state:
        st.warning("Ã–nce belge yÃ¼kleyin.")
    else:
        if api_key:
            # GÃœNCELLENEN KISIM: Model ismi deÄŸiÅŸti
            llm = ChatGoogleGenerativeAI(
                model="gemini-1.5-flash-latest", 
                google_api_key=api_key, 
                temperature=0.3
            )
            
            prompt_template = """
            Sen uzman bir Orman MÃ¼hendisi asistanÄ±sÄ±n.
            BaÄŸlam: {context}
            Soru: {question}
            Cevap:
            """
            PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
            
            qa_chain = RetrievalQA.from_chain_type(
                llm=llm,
                chain_type="stuff",
                retriever=st.session_state.vector_store.as_retriever(),
                chain_type_kwargs={"prompt": PROMPT}
            )
            
            with st.spinner("Cevap hazÄ±rlanÄ±yor..."):
                try:
                    cevap = qa_chain.run(soru)
                    st.write(cevap)
                except Exception as e:
                    st.error(f"Hata: {e}")
