import streamlit as st
import os
import tempfile
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# Sayfa AyarlarÄ±
st.set_page_config(page_title="Orman Mevzuat AsistanÄ±", layout="wide", page_icon="ğŸŒ²")

# BaÅŸlÄ±k ve AÃ§Ä±klama
st.title("ğŸŒ² Orman Mevzuat AsistanÄ± (AI)")
st.markdown("""
Bu asistan, **Google Gemini** altyapÄ±sÄ±nÄ± kullanarak yÃ¼klediÄŸiniz ormancÄ±lÄ±k mevzuatÄ±nÄ± analiz eder.
YÃ¶netmelik, kanun veya tebliÄŸ PDF'lerini yÃ¼kleyin ve sorun.
""")

# Yan MenÃ¼ (Sidebar) - Dosya YÃ¼kleme AlanÄ±
st.sidebar.header("ğŸ“ Belge YÃ¼kle")
api_key = st.secrets["GOOGLE_API_KEY"] # API AnahtarÄ±nÄ± gÃ¼venli alandan Ã§ekeceÄŸiz

uploaded_files = st.sidebar.file_uploader("Mevzuat PDF'lerini Buraya SÃ¼rÃ¼kleyin", accept_multiple_files=True, type="pdf")

# Buton
process_button = st.sidebar.button("Belgeleri Ä°ÅŸle ve HazÄ±rla")

# Ana Fonksiyonlar
if process_button and uploaded_files:
    if not api_key:
        st.error("LÃ¼tfen API anahtarÄ±nÄ±zÄ± tanÄ±mlayÄ±n!")
    else:
        with st.spinner("Belgeler taranÄ±yor ve yapay zeka iÃ§in hazÄ±rlanÄ±yor..."):
            documents = []
            # PDF'leri geÃ§ici olarak kaydet ve oku
            for uploaded_file in uploaded_files:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_file:
                    temp_file.write(uploaded_file.read())
                    temp_file_path = temp_file.name

                loader = PyPDFLoader(temp_file_path)
                docs = loader.load()
                documents.extend(docs)
                os.remove(temp_file_path) # Temizlik

            # Metinleri parÃ§alara bÃ¶l (Chunking)
            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            splits = text_splitter.split_documents(documents)

            # VektÃ¶r VeritabanÄ± OluÅŸtur (Embeddings)
            embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
            vector_store = FAISS.from_documents(splits, embeddings)
            
            # VeritabanÄ±nÄ± oturuma kaydet (Session State)
            st.session_state.vector_store = vector_store
            st.success(f"TamamlandÄ±! Toplam {len(splits)} parÃ§aya bÃ¶lÃ¼ndÃ¼. ArtÄ±k soru sorabilirsiniz.")

# Soru Sorma AlanÄ±
soru = st.text_input("Mevzuat ile ilgili sorunuz nedir?", placeholder="Ã–rn: 6831 sayÄ±lÄ± kanuna gÃ¶re iÅŸgal ve faydalanma suÃ§u nedir?")

if soru:
    if "vector_store" not in st.session_state:
        st.warning("LÃ¼tfen Ã¶nce sol menÃ¼den PDF yÃ¼kleyin ve 'Ä°ÅŸle' butonuna basÄ±n.")
    else:
        # Model AyarlarÄ± (Gemini 1.5 Flash)
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", google_api_key=api_key, temperature=0.3)
        
        # Ã–zel Prompt (Yapay Zekaya Rol Verme)
        prompt_template = """
        Sen uzman bir Orman MÃ¼hendisi asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki baÄŸlamÄ± (context) kullanarak kullanÄ±cÄ±nÄ±n sorusunu cevapla.
        Cevap verirken ilgili kanun maddesine veya yÃ¶netmelik bÃ¶lÃ¼mÃ¼ne atÄ±f yapmaya Ã§alÄ±ÅŸ.
        EÄŸer bilgi metinlerde yoksa "Bu bilgi yÃ¼klenen belgelerde bulunamadÄ±" de.
        
        BaÄŸlam: {context}
        Soru: {question}
        
        Cevap:
        """
        PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        
        # Zinciri Kurma
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=st.session_state.vector_store.as_retriever(),
            chain_type_kwargs={"prompt": PROMPT}
        )
        
        with st.spinner("Mevzuat taranÄ±yor..."):
            cevap = qa_chain.run(soru)
            st.write("### ğŸ¤– AsistanÄ±n CevabÄ±:")
            st.write(cevap)